import pandas as pd
import anndata
import numpy as np
import sklearn
import anndata
import os
import gc
import scanpy as sc
import sys
import os, re
from typing import List, Dict, Optional

# è¿ç§»å®Œæˆï¼ˆä»…data_splitï¼‰

from ktplotspy.utils.support import (
    ensure_categorical, # å¼ºåˆ¶categoricalåŒ–pd.Dataframe
    filter_interaction_and_celltype,
    hclust,
    prep_celltype_query,
    prep_query_group,
    prep_table, # ç”¨äºæ ¼å¼åŒ–å‡å€¼å’Œ pvalues è¡¨çš„é€šç”¨å‡½æ•°
    set_x_stroke,
    sub_pattern,
)

from plotnine import *

# é‰´äº https://github.com/zktuong/ktplotspy/blob/master/ktplotspy/utils/settings.py ç¡¬ç¼–ç äº†CPDBæ•°æ®å¤„ç†çš„å¿…è¦ä¿¡æ¯
# æˆ‘ä»¬ç›´æ¥æŠŠå®ƒä»¬æ‹·è´è¿‡æ¥æ¯”è¾ƒå¥½debug
DEFAULT_SEP = ">@<"
DEFAULT_SPEC_PAT = "/|:|\\?|\\*|\\+|\\(|\\)|\\/|\\[|\\]\\-"
DEFAULT_CELLSIGN_ALPHA = 0.5
DEFAULT_COLUMNS = ["interaction_group", "celltype_group"]
DEFAULT_V5_COL_START = 13
DEFAULT_COL_START = 11
DEFAULT_CLASS_COL = 12
DEFAULT_CPDB_SEP = "|"

def filter_by_frequency(data, column, min_count):
    """
    æ ¹æ®ç‰¹å®šåˆ—ä¸­å€¼çš„é¢‘ç‡è¿‡æ»¤ DataFrame æˆ– AnnData å¯¹è±¡ä¸­çš„è¡Œã€‚

    Parameters:
    ----------
    data : pd.DataFrame or AnnData
        The data object to filter. For AnnData, filtering is applied on `data.obs`.
    column : str
        The name of the column to calculate value frequencies.
    min_count : int
        The minimum frequency required to keep a value.

    Returns:
    -------
    filtered_data : same type as input (pd.DataFrame or AnnData)
        The filtered data object containing only rows with values meeting the frequency threshold.
    """
    # Determine the value counts
    value_counts = data.obs[column].value_counts() if hasattr(data, "obs") else data[column].value_counts()
    
    # Get values meeting the frequency threshold
    keep_values = value_counts[value_counts > min_count].index
    
    # Filter the data based on the threshold
    if hasattr(data, "obs"):  # If the input is AnnData
        return data[data.obs[column].isin(keep_values)]
    else:  # If the input is a DataFrame
        return data[data[column].isin(keep_values)]


def data_split(adata, disease, data_path, downsample_by_key,min_count=30,
               downsample=True, max_cells=2000,random_state=0,
               use_raw=False):
    '''
    ç”¨æ¥æŒ‰ç…§ç–¾ç—…æ‹†åˆ†adataæ–‡ä»¶ã€å»é™¤ä½é¢‘äºšç¾¤ï¼Œå¹¶ç”Ÿæˆcellphonedbæ‰€éœ€æ–‡ä»¶

    :param adata: è¾“å…¥ AnnData å¯¹è±¡
    :param disease: è¦ç­›é€‰çš„ç–¾ç—…ç»„å
    :param data_path: è¾“å‡ºæ–‡ä»¶å¤¹çš„æ ¹è·¯å¾„
    :param min_count: ä½äºæ­¤æ•°é‡çš„ Subset_Identity ä¼šè¢«ç§»é™¤
    :param use_raw: æ˜¯å¦ä½¿ç”¨ adata.raw.X æ¥ä¿å­˜è¡¨è¾¾çŸ©é˜µ
    :return: è¾“å‡º counts.h5ad å’Œ metadata.tsvï¼Œå¹¶ä¿å­˜ adata_subset
    '''
    print(f"\nâ¡ï¸ å½“å‰å¤„ç†ç–¾ç—…ç»„: {disease}")
    
    np.random.seed(random_state)
    
    # 1. æ ¹æ®ç–¾ç—…åç§°ç­›é€‰æ•°æ®
    adata_subset = adata[adata.obs["disease"] == disease].copy()
    print(f"åŸå§‹ç»†èƒæ•°: {adata_subset.shape[0]}")
    
    # 2. æ£€æŸ¥ Subset_Identity åˆ—æ˜¯å¦å­˜åœ¨
    if 'Subset_Identity' not in adata_subset.obs.columns:
        raise KeyError("'Subset_Identity' column not found in adata.obs")
    
    # 3. æ ¹æ®é¢‘ç‡è¿‡æ»¤äºšç¾¤
    subset_counts = adata_subset.obs["Subset_Identity"].value_counts()
    valid_subsets = subset_counts[subset_counts >= min_count].index
    adata_subset = adata_subset[adata_subset.obs["Subset_Identity"].isin(valid_subsets)].copy()
    print(f"è¿‡æ»¤åç»†èƒæ•°: {adata_subset.shape[0]}")
    
    if downsample:
        selected_indices = []
        for group, idx in adata_subset.obs.groupby(downsample_by_key).indices.items():
            if len(idx) > max_cells:
                sampled = np.random.choice(idx, max_cells, replace=False)
            else:
                sampled = idx
            selected_indices.extend(sampled)
        
        adata_subset = adata_subset[selected_indices].copy()
        print(f"ä¸‹é‡‡æ ·åç»†èƒæ•°: {adata_subset.shape[0]}")
    
    # ğŸ” æ‰“å°ä¿ç•™ä¸‹æ¥çš„ cluster
    print("âœ… ä¿ç•™çš„ Subset_Identity:")
    print(adata_subset.obs["Subset_Identity"].value_counts())
    
    # 4. å‡†å¤‡è¾“å‡ºè·¯å¾„
    disease_dir = os.path.join(data_path, disease)
    os.makedirs(disease_dir, exist_ok=True)
    
    # 5. ä¿å­˜ metadata.tsv
    meta_file = pd.DataFrame({
        'Cell': adata_subset.obs.index,
        'cell_type': adata_subset.obs["Subset_Identity"]
    })
    meta_file_path = os.path.join(disease_dir, "metadata.tsv")
    meta_file.to_csv(meta_file_path, index=False, sep="\t")
    
    # 6. é€‰æ‹©è¡¨è¾¾çŸ©é˜µï¼šraw or not
    if use_raw:
        if adata.raw is None:
            raise ValueError("adata.raw is None, cannot use raw matrix.")
        X = adata.raw[adata_subset.obs_names].X
        var = adata.raw.var.copy()
    else:
        X = adata_subset.X
        var = adata_subset.var.copy()
    
    # æ·»åŠ åŸºå› åå­—æ®µï¼ŒCellPhoneDB å¯èƒ½éœ€è¦
    var["gene_name"] = var.index
    
    # 7. åˆ›å»ºæ–° AnnData å¹¶ä¿å­˜f
    adata_out = sc.AnnData(
        X=X,
        obs=adata_subset.obs.copy(),
        var=var
    )
    count_file_path = os.path.join(disease_dir, "counts.h5ad")
    adata_out.write(count_file_path)
    
    print(f"ğŸ“ æ–‡ä»¶ä¿å­˜è‡³: {count_file_path} ä¸ {meta_file_path}")


#
def find_file(file_dir, pattern):
    """ç”¨æ¥ç®€å•å¿«é€Ÿåœ°ç”¨æ–‡æ¡£å¼€å¤´æ¥åŒ¹é…æ–‡æ¡£"""
    files = os.listdir(file_dir)
    for file in files:
        if re.search(pattern, file):
            return os.path.join(file_dir, file)
    raise FileNotFoundError(f"No file matching pattern '{pattern}' found in {file_dir}")


def extract_cpdb_result(file_dir):
    '''
    ä»è¾“å‡ºç›®å½•ä¸‹è¯»å–CPDBç»“æœï¼Œå®é™…ä¸Šä¹Ÿå°±æ˜¯æ¢å¤cpdb_analysis_methodç›´æ¥è¿”å›çš„å¯¹è±¡ ï¼ˆæ£€æŸ¥å¯ç”¨ï¼‰
    
    ä½¿ç”¨ä¾‹ï¼šresult = extract_cpdb_result('/path/to/cpdb/results')
    :param file_dir: è¾“å‡ºæ–‡ä»¶
    :return: è¿”å›åŒ…å«è¾“å‡ºå†…å®¹çš„å­—å…¸
    '''
    
    # Define the patterns for each type of result
    file_patterns = {
        'deconvoluted_percents': "analysis_deconvoluted_percents",
        'deconvoluted': "analysis_deconvoluted",
        'means': "analysis_means",
        'pvalues': "analysis_pvalues|analysis_relevant_interactions",
        'interaction_scores': "analysis_interaction_scores",
        'significant_means': "analysis_significant_means",
    }
    
    # Load the files into a dictionary
    cpdb_results = {}
    for key, pattern in file_patterns.items():
        file_path = find_file(file_dir, pattern)
        cpdb_results[key] = pd.read_table(file_path, delimiter='\t')
    
    return cpdb_results


def retrieve_name(var):
    '''
    è·å–å˜é‡çš„åç§°
    æ›´æ–°ï¼šæ£€æŸ¥è¾“å…¥å˜é‡ç±»å‹æ˜¯å¦æ˜¯å“ˆå¸Œä¸å¯å˜ç±»å‹ï¼ˆå¦‚æ•´æ•°ã€å­—ç¬¦ä¸²ï¼‰ï¼Œé¿å…å¸¸é‡æ± çš„é—®é¢˜ã€‚
    :param var: å˜é‡å
    :return: "var"
    '''
    var_id = id(var)
    callers_local_vars = inspect.currentframe().f_back.f_locals.items()
    return [var_name for var_name, var_val in callers_local_vars if id(var_val) == var_id]




## ä»¥ä¸‹éƒ½æ˜¯extract_cpdb_tableçš„è¾…åŠ©å‡½æ•°ï¼Œå¤§éƒ¨åˆ†ä¼šåœ¨å°†æ¥å†…éƒ¨åŒ–æˆ–æ”¾å…¥CPDB_util.pyä¸­
def align_pvals_to_means(means_mat, pvals_mat, degs_analysis, col_start = DEFAULT_V5_COL_START):
    """
    å‡†å¤‡p-values matrixï¼Œä»¥ä¾¿äºåé¢å’Œmeans matrixå¯¹é½ã€‚
    """
    if pvals_mat.shape != means_mat.shape:
        tmp_pvals = pd.DataFrame(index=means_mat.index, columns=means_mat.columns)
        tmp_pvals.iloc[:, :col_start] = means_mat.iloc[:, :col_start]
        tmp_pvals.update(pvals_mat)
        tmp_pvals.fillna(0 if degs_analysis else 1, inplace=True)
        return tmp_pvals
    return pvals_mat
    
def prepare_input(cpdb_outcome_dict, degs_analysis, col_start = DEFAULT_V5_COL_START,cellsign=None):
    means = prep_table(data=cpdb_outcome_dict["means"])
    pvals = prep_table(data=cpdb_outcome_dict["pvalues"])
    interaction_scores = cpdb_outcome_dict["interaction_scores"]
    if interaction_scores is not None:
        interaction_scores_mat = prep_table(data=interaction_scores)
        cellsign_mat = []
    else:
        interaction_scores_mat = []
        if cellsign is not None:
            cellsign_mat = prep_table(data=cellsign)
        else:
            cellsign_mat = []
    
    if pvals.shape != means.shape:
        # è¿™ä¸€æ­¥å¤§éƒ¨åˆ†æƒ…å†µæ˜¯ç¬¦åˆçš„ï¼Œåè€Œä¸å¤ªæ¸…æ¥šä¸ç¬¦åˆçš„æƒ…å†µï¼Œå› æ­¤è°ƒç”¨è¿™ä¸ªå‡½æ•°çš„æ—¶å€™æˆ‘ä»¬ä¸»åŠ¨æŠ¥å‘Šä¸€ä¸‹
        print("Warning: P-val and Means matrices are not in the same shape.")
        pvals = align_pvals_to_means(means_mat=means, pvals_mat=pvals, col_start=col_start,
                                     degs_analysis=degs_analysis)
    
    return means, pvals, interaction_scores, interaction_scores_mat, cellsign_mat
    
def prepare_metadata(adata_obs, celltype_key, splitby_key):
    """
    å¤„ç†adata.obsä¸­çš„metadataï¼Œç¡®ä¿celltype_keyå’Œsplitby_keyåˆ—ä¸ºåˆ†ç±»å˜é‡ï¼ˆcategoricalï¼‰ã€‚
    å¹¶æ ¹æ®splitby_keyæ˜¯å¦å­˜åœ¨ï¼Œç”Ÿæˆç»„åˆæ ‡ç­¾'_labels'ç”¨äºåç»­åˆ†æã€‚

    å‚æ•°ï¼š
    - adata_obs: pandas.DataFrameï¼Œadata.obsçš„æ•°æ®å‰¯æœ¬
    - celltype_key: strï¼Œç»†èƒç±»å‹æ‰€åœ¨çš„åˆ—å
    - splitby_key: stræˆ–Noneï¼Œç”¨äºæ‹†åˆ†çš„åˆ—åï¼Œå¦‚æœä¸ºNoneï¼Œåˆ™åªç”¨celltype_key

    è¿”å›ï¼š
    - metadata: å¤„ç†åå¸¦æœ‰'_labels'åˆ—çš„DataFrame
    """

    # å¤åˆ¶adata.obsï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    metadata = adata_obs.copy()

    # ç¡®ä¿celltype_keyå¯¹åº”çš„åˆ—ä¸ºåˆ†ç±»å˜é‡
    metadata = ensure_categorical(metadata, celltype_key)

    # å¦‚æœæŒ‡å®šäº†æ‹†åˆ†åˆ—splitby_key
    if splitby_key:
        # ç¡®ä¿splitby_keyå¯¹åº”çš„åˆ—ä¸ºåˆ†ç±»å˜é‡
        metadata = ensure_categorical(metadata, splitby_key)
        
        # ç”Ÿæˆæ–°åˆ—'_labels'ï¼Œå€¼ä¸ºsplitby_keyä¸celltype_keyçš„å­—ç¬¦ä¸²æ‹¼æ¥ï¼Œä¸­é—´ç”¨ä¸‹åˆ’çº¿è¿æ¥
        metadata["_labels"] = metadata[splitby_key] + "_" + metadata[celltype_key]
        
        # å°†'_labels'åˆ—è½¬ä¸ºåˆ†ç±»å˜é‡
        metadata["_labels"] = metadata["_labels"].astype("category")
        
        # é‡æ–°å®šä¹‰åˆ†ç±»é¡ºåºï¼Œé¡ºåºä¸ºæ‰€æœ‰splitby_keyåˆ†ç±» * æ‰€æœ‰celltype_keyåˆ†ç±»çš„ç»„åˆ
        # ä»…ä¿ç•™å®é™…å­˜åœ¨äº'_labels'ä¸­çš„ç»„åˆ
        cat_orders = [
            f"{s}_{c}"
            for s in metadata[splitby_key].cat.categories
            for c in metadata[celltype_key].cat.categories
            if f"{s}_{c}" in metadata._labels.values
        ]
        
        # æŒ‰ç…§cat_ordersé¡ºåºé‡æ–°æ’åº'_labels'åˆ†ç±»
        metadata["_labels"] = metadata["_labels"].cat.reorder_categories(cat_orders)
    
    else:
        # å¦‚æœæ²¡æœ‰splitby_keyï¼Œåˆ™ç›´æ¥å°†celltype_keyåˆ—èµ‹å€¼ç»™'_labels'
        metadata["_labels"] = metadata[celltype_key]
    
    return metadata

def validate_inputs(interaction_scores, cellsign, genes, gene_family):
    if interaction_scores is not None and cellsign is not None:
        raise KeyError("Please specify either interaction scores or cellsign, not both.")
    if genes is not None and gene_family is not None:
        raise KeyError("Please specify either genes or gene_family, not both.")

def get_gene_query(means_mat: pd.DataFrame, genes: Optional[List[str]] = None, gene_family: Optional[str] = None,
                   custom_gene_family: Optional[Dict[str, List[str]]] = None, debug: Optional[bool]=False) -> List[str]:
    """
    Get a list of genes based on either 'genes' or 'gene_family'.

    Parameters
    ----------
    means_mat : pd.DataFrame
        DataFrame containing at least the 'interacting_pair' column.
    genes : Optional[List[str]], optional
        List of genes to query.
    gene_family : Optional[str], optional
        Predefined gene family to query.
    custom_gene_family : Optional[Dict[str, List[str]]], optional
        Custom gene family definitions.

    Returns
    -------
    List[str]
        List of genes matching the query.
    """
    print("Starting generate ligand-receptor pair query.")
    
    def validate_gene_family(gene_family: str, query_group: Dict) -> List[str]:
        """Validate and retrieve genes for a given gene family."""
        if gene_family.lower() in query_group:
            return query_group[gene_family.lower()]
        raise KeyError(f"gene_family must be one of the following: {list(query_group.keys())}")
    
    if genes is None:
        if gene_family is not None:
            query_group = prep_query_group(means_mat, custom_gene_family)
            if isinstance(gene_family, list):
                query = []
                for gf in gene_family:
                    query += validate_gene_family(gf, query_group)
                query = list(set(query))  # Remove duplicates
            else:
                query = validate_gene_family(gene_family, query_group)
        else:
            # Default: Return all genes
            query = [i for i in means_mat.interacting_pair if re.search("", i)]
    elif genes is not None:
        if gene_family is not None:
            raise KeyError("Please specify either 'genes' or 'gene_family', not both.")
        else:
            # Match genes in the interacting_pair column
            query = [i for i in means_mat.interacting_pair if re.search("|".join(genes), i)]
    print(f"Found {len(query)} different gene queires.")
    if debug:
        print("#" * 16)
        print("Head 10s of all gene queries:")
        print(query[0:10])
        print("#" * 16)
    return query

def generate_celltype_patterns(c_type1: List[str], c_type2: List[str], lock_celltype_direction: bool,
                               splitby_key: Optional[str], groups: List[str],debug) -> List[str]:
    """
    ç”Ÿæˆç»†èƒç±»å‹çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼Œæ ¹æ®é”å®šæ–¹å‘å’Œåˆ†ç»„æ¡ä»¶ç­›é€‰ç»„åˆã€‚

    Parameters
    ----------
    c_type1 : List[str]
        ç¬¬ä¸€ç»„ç»†èƒç±»å‹ã€‚
    c_type2 : List[str]
        ç¬¬äºŒç»„ç»†èƒç±»å‹ã€‚
    lock_celltype_direction : bool
        æ˜¯å¦é”å®šç»†èƒç±»å‹çš„æ–¹å‘æ€§ã€‚
    splitby_key : Optional[str]
        åˆ†ç»„çš„é”®å€¼ï¼Œè‹¥ä¸º None åˆ™ä¸è¿›è¡Œåˆ†ç»„ç­›é€‰ã€‚
    groups : List[str]
        åˆ†ç»„çš„åˆ—è¡¨ï¼›åªæœ‰å½“splitby_keyç»™å®šå‚æ•°æ—¶æ‰ä¼šäº§ç”Ÿ
    DEFAULT_SEP : str
        ç»†èƒç±»å‹ä¹‹é—´çš„åˆ†éš”ç¬¦ã€‚

    Returns
    -------
    List[str]
        ç”Ÿæˆçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼åˆ—è¡¨ã€‚
    """
    celltype_patterns = []
    
    # ç”ŸæˆåŸºç¡€ç»„åˆæ¨¡å¼
    for cell1 in c_type1:
        cq = [
            f"^{cell1}{DEFAULT_SEP}{cell2}$" for cell2 in c_type2
        ]
        if not lock_celltype_direction:  # åŒå‘ç»„åˆ
            cq.extend(
                f"^{cell2}{DEFAULT_SEP}{cell1}$" for cell2 in c_type2
            )
        combined_patterns = "|".join(cq)
        
        if splitby_key is not None:  # æŒ‰åˆ†ç»„è¿‡æ»¤
            for group in groups:
                filtered_patterns = [
                    pattern for pattern in cq
                    if re.search(f"{group}.*{DEFAULT_SEP}{group}", pattern)
                ]
                if filtered_patterns:
                    celltype_patterns.append("|".join(filtered_patterns))
        else:  # æ— åˆ†ç»„æ—¶ç›´æ¥æ·»åŠ 
            celltype_patterns.append(combined_patterns)
    
    if debug:
        print("#" * 16)
        print("Celltype_1:")
        print(*c_type1,sep=",")
        print("#" * 16)
        print("Celltype_2:")
        print(*c_type2,sep=",")
        print("#" * 16)
    return celltype_patterns

def get_cell_query(metadata, means_mat, cell_type1, cell_type2, lock_celltype_direction, splitby_key,
                   special_character_regex_pattern,debug):
    print("Starting generate cell pair query.")
    All_labels = list(metadata._labels.cat.categories)
    
    # å°†cell_typeå¯èƒ½åŒ…å«çš„ç‰¹æ®Šå­—ç¬¦è½¬ä¹‰
    if special_character_regex_pattern is None:
        special_character_regex_pattern = DEFAULT_SPEC_PAT
    
    All_labels = [sub_pattern(cell_type=labels, pattern=special_character_regex_pattern) for labels in All_labels]
    cell_type1 = sub_pattern(cell_type=cell_type1, pattern=special_character_regex_pattern)
    cell_type2 = sub_pattern(cell_type=cell_type2, pattern=special_character_regex_pattern)
    c_type1 = cell_type1 if cell_type1 != "." else All_labels
    c_type2 = cell_type2 if cell_type2 != "." else All_labels
    groups = list(metadata[splitby_key].cat.categories) if splitby_key else None
    
    # ç”Ÿæˆæ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ç»†èƒå¯¹
    All_valid_cellpair = generate_celltype_patterns(c_type1, c_type2, lock_celltype_direction, splitby_key,
                                                    groups=groups,debug=debug)
    if debug:
        print("#" * 16)
        print("Head of All_valid_cellpair:")
        print(All_valid_cellpair[0:10])
        print("#" * 16)
    # All_valid_cellpair = "|".join(All_valid_cellpair)
    compiled_patterns = [re.compile(pattern) for pattern in All_valid_cellpair]
    print(f"There are {len(All_valid_cellpair)} possible celltype interactions.")
    
    # ä»ç»“æœä¸­æŠ½å‡ºç¬¦åˆæ¡ä»¶çš„ï¼Œå³ï¼šå–äº¤é›†
    # ct_columns = [ct for ct in means_mat.columns if re.search(All_valid_cellpair, ct)]
    ct_columns = [
        ct for ct in means_mat.columns
        if any(pattern.search(ct) for pattern in compiled_patterns)
    ]
    print(f"Found {len(ct_columns)} different celltype queires.")
    return ct_columns, groups

def get_col_order(columns, groups=None):
    """
    è·å–åˆ—çš„é¡ºåºï¼Œæ ¹æ® groups è¿›è¡Œç­›é€‰ã€‚
    Parameters
    ----------
    columns : pd.Index
        æ•°æ®çŸ©é˜µçš„åˆ—åã€‚
    groups : List[str], optional
        åˆ†ç»„åç§°åˆ—è¡¨ï¼Œç”¨äºæ­£åˆ™åŒ¹é…åˆ—åã€‚
    Returns
    -------
    List[str]
        ç­›é€‰åçš„åˆ—é¡ºåºã€‚
    """
    if groups:
        return [c for g in groups for c in columns if re.search(g, c)]
    return list(columns)

def filter_data(means_mat, pvals_mat, interaction_scores,interaction_scores_mat, cellsign,
                gene_query, cell_query,
                keep_significant_only,groups,alpha,debug):
    '''æ ¸å¿ƒæ˜¯åŒ…è£…çš„filter_interaction_and_celltypeå‡½æ•°'''
    if debug:
        print("#" * 16)
        print("Gene queries:")
        print(gene_query)
        print("#" * 16)
        print("Cell queries:")
        print(cell_query)
        print("#" * 16)
    # è¿‡æ»¤ä¸»è¦çŸ©é˜µ
    means_matx = filter_interaction_and_celltype(data=means_mat, genes=gene_query, celltype_pairs=cell_query)
    pvals_matx = filter_interaction_and_celltype(data=pvals_mat, genes=gene_query, celltype_pairs=cell_query)
    # è¿‡æ»¤å…¶ä»–çŸ©é˜µ
    if interaction_scores is not None:
        interaction_scores_matx = filter_interaction_and_celltype(data=interaction_scores_mat, genes=gene_query,
                                                                  celltype_pairs=cell_query)
    elif cellsign is not None:
        cellsign_matx = filter_interaction_and_celltype(data=cellsign_mat, genes=gene_query, celltype_pairs=cell_query)
    
    # è°ƒæ•´åˆ—çš„é¡ºåºï¼Œä»¥å¯¹é½çŸ©é˜µ
    col_order = get_col_order(means_matx.columns, groups)
    if debug:
        print("#" * 16)
        print(col_order)
        print("#" * 16)
    # åº”ç”¨åˆ—é¡ºåºåˆ°çŸ©é˜µ
    means_matx = means_matx[col_order]
    pvals_matx = pvals_matx[col_order]
    # æ›´æ–°å…¶ä»–çŸ©é˜µ
    if interaction_scores is not None:
        interaction_scores_matx = interaction_scores_matx[col_order]
        cellsign_matx = []
    elif cellsign is not None:
        interaction_scores_matx = []
        cellsign_matx = cellsign_matx[col_order]
    else:
        interaction_scores_matx = []
        cellsign_matx = []
    if keep_significant_only:
        # ç­›é€‰å‡ºä»»æ„åˆ—ä¸­ p å€¼å°äº alpha çš„è¡Œ
        keep_rows = pvals_matx.index[pvals_matx.lt(alpha).any(axis=1)]
        
        if keep_rows.size > 0:
            print(f"After significance filtering, there are {keep_rows.size} lines remain.")
            # æ›´æ–°ä¸»è¦çŸ©é˜µ
            pvals_matx = pvals_matx.loc[keep_rows]
            means_matx = means_matx.loc[keep_rows]
            if debug:
                print("#" * 16)
                print("Kept rows are:")
                print(keep_rows)
                print("#" * 16)
            # æ›´æ–°interaction_scoreså’Œcellsign
            if interaction_scores is not None:
                interaction_scores_matx = interaction_scores_matx.loc[keep_rows]
            
            if cellsign is not None:
                cellsign_rows = keep_rows.intersection(cellsign_matx.index)
                if cellsign_rows.size > 0:
                    cellsign_matx = cellsign_matx.loc[cellsign_rows]
                else:
                    raise ValueError("Your cellsign data may not contain significant hits.")
        else:
            raise ValueError("No significant rows found in the data.")
    return means_matx, pvals_matx, interaction_scores_matx, cellsign_matx

def cluster_rows_by_means(means_matx, pvals_matx, interaction_scores, interaction_scores_matx, cellsign,
                          cellsign_matx):
    if means_matx.shape[0] > 2:
        # è¡Œèšç±»è·å–é¡ºåº
        h_order = hclust(means_matx, axis=0)
        print("Hclust algorithm processed successfully.")
        # Index = 0 and columns = 1ï¼Œå¯¹è¡Œè¿›è¡Œå±‚æ¬¡èšç±»
        # å¯¹ä¸»è¦çŸ©é˜µé‡æ–°æ’åº
        means_matx = means_matx.loc[h_order]
        pvals_matx = pvals_matx.loc[h_order]
        # å¯¹ interaction_scores å’Œ cellsign æ•°æ®å¤„ç†
        if interaction_scores is not None:
            interaction_scores_matx = interaction_scores_matx.loc[h_order]
        elif cellsign is not None:
            # ä»…ä¿ç•™ cellsign_matx ä¸­å­˜åœ¨çš„è¡Œ
            valid_h_order = [h for h in h_order if h in cellsign_matx.index]
            if valid_h_order:
                cellsign_matx = cellsign_matx.loc[valid_h_order]
            else:
                raise ValueError(
                    "No significant hits found in cellsign data after clustering. "
                    "Ensure cellsign_matx contains matching rows."
                )
    return means_matx, pvals_matx, interaction_scores_matx, cellsign_matx

def standardize_means(means_matx):
    # çŸ¢é‡åŒ–æ“ä½œè¿›è¡Œè¡Œæ ‡å‡†åŒ–
    row_min = means_matx.min(axis=1)  # æŒ‰è¡Œæ±‚æœ€å°å€¼
    row_max = means_matx.max(axis=1)  # æŒ‰è¡Œæ±‚æœ€å¤§å€¼
    range_diff = row_max - row_min  # è®¡ç®—èŒƒå›´
    
    # é¿å…åˆ†æ¯ä¸º 0 çš„è¡Œ
    range_diff[range_diff == 0] = 1
    
    means_matx = (means_matx.sub(row_min, axis=0)).div(range_diff, axis=0)
    return means_matx

def finalize_output(means_matx, pvals_matx, interaction_scores, interaction_scores_matx, cellsign, cellsign_matx,
                    col_start,standard_scale, additional_grouping, exclude_interactions, keep_significant_only,alpha,
                    keep_id_cp_interaction=False):
    # ç¡®å®šåˆ—å
    colm = "scaled_means" if standard_scale else "means"
    
    # è½¬æ¢ä¸ºé•¿æ ¼å¼å¹¶è®¾ç½®ç´¢å¼•
    df = means_matx.melt(ignore_index=False).reset_index()
    df.index = df["index"] + DEFAULT_SEP * 3 + df["variable"]
    df.columns = DEFAULT_COLUMNS + [colm]
    
    df_pvals = pvals_matx.melt(ignore_index=False).reset_index()
    df_pvals.index = df_pvals["index"] + DEFAULT_SEP * 3 + df_pvals["variable"]
    df_pvals.columns = DEFAULT_COLUMNS + ["pvals"]
    
    # åˆå¹¶ pvals
    df["pvals"] = df_pvals["pvals"]
    
    # åˆå¹¶ interaction_scores æˆ– cellsign
    if interaction_scores is not None:
        df_interaction_scores = interaction_scores_matx.melt(ignore_index=False).reset_index()
        df_interaction_scores.index = df_interaction_scores["index"] + DEFAULT_SEP * 3 + df_interaction_scores[
            "variable"]
        df_interaction_scores.columns = DEFAULT_COLUMNS + ["interaction_scores"]
        df["interaction_scores"] = df_interaction_scores["interaction_scores"]
    elif cellsign is not None:
        df_cellsign = cellsign_matx.melt(ignore_index=False).reset_index()
        df_cellsign.index = df_cellsign["index"] + DEFAULT_SEP * 3 + df_cellsign["variable"]
        df_cellsign.columns = DEFAULT_COLUMNS + ["cellsign"]  # same as above.
        df["cellsign"] = df_cellsign["cellsign"]
    
    # åˆ†ç±»å˜é‡è½¬æ¢
    df["celltype_group"] = df["celltype_group"].str.replace(DEFAULT_SEP, "-").astype("category")
    df[["cell_left", "cell_right"]] = df["celltype_group"].str.split("-", expand=True)
    
    # æ ‡å‡†åŒ–ä¸æ˜¾è‘—æ€§è¿‡æ»¤
    df[colm] = df[colm].replace(0, np.nan)  # æ›¿æ¢ä¸º NaN
    df["x_means"] = df[colm]
    df["y_means"] = df[colm]
    
    # çŸ¢é‡åŒ–æ“ä½œå¤„ç†æ˜¾è‘—æ€§
    df.loc[df["pvals"] < alpha, "x_means"] = np.nan
    df.loc[df["pvals"] == 0, "pvals"] = 0.001
    if keep_significant_only:
        # ä»…ä¿ç•™æ˜¾è‘—æ€§è¾ƒé«˜çš„è¡Œ
        df = df[df["pvals"] < alpha]
    
    
    if interaction_scores is not None:
        df.loc[df["interaction_scores"] < 1, "x_means"] = np.nan
    elif cellsign is not None:
        df.loc[df["cellsign"] < 1, "cellsign"] = DEFAULT_CELLSIGN_ALPHA
    
    # é¢å¤–å…ƒæ•°æ®æ·»åŠ 
    if col_start == DEFAULT_V5_COL_START and additional_grouping:
        df["is_integrin"] = df.index.map(is_int)
        df["directionality"] = df.index.map(direc)
        df["classification"] = df.index.map(classif)
    
    # æ˜¾è‘—æ€§æ ‡è®°ç­‰
    df["neglog10p"] = -np.log10(df["pvals"].clip(lower=alpha))
    df["significant"] = np.where(df["pvals"] < alpha, "yes", "no")
        # åŸå‡½æ•°è¿”å›nançš„è¡Œä¸ºä»¤äººè¿·æƒ‘â€¦â€¦é™¤äº†æ–¹ä¾¿æ£€æŸ¥æ˜¯å¦éƒ½isnullåˆ°åº•è¿˜æœ‰ä»€ä¹ˆç”¨
    
    # æ’é™¤æŒ‡å®šinteraction_group
    if exclude_interactions:
        exclude_interactions = exclude_interactions if isinstance(exclude_interactions, list) else [
            exclude_interactions]
        df = df[~df["interaction_group"].isin(exclude_interactions)]
    
    # é‡å†™interaction_groupçš„åå­—
        # æ‹†åˆ†è¿”å›å¯èƒ½æ˜¯ä¸¤åˆ—æˆ–è€…ä¸‰åˆ—
    if keep_id_cp_interaction:
        df.interaction_group = [re.sub(DEFAULT_SEP * 3, "_", c) for c in df.interaction_group]
            # é—´éš”ç¬¦ä¸º id_a-b-cï¼Œ ä¸è¿›è¡Œæ‹†åˆ†
    else:
        df.interaction_group = [c.split(DEFAULT_SEP * 3)[1] for c in df.interaction_group]
        
        
        
        
    # Acetylcholine-byCHAT-CHRM3
        
    
    
    # è¾“å‡ºç»“æœ
    if df.empty:
        print("The result is empty in this case.")
    else:
        return df

def extract_cpdb_table(
        metadata,
        cell_type1: str,
        cell_type2: str,
        cpdb_outcome_dict,
        cellsign=None,
        degs_analysis: bool = False,
        splitby_key=None,
        alpha: float = 0.05,
        min_interaction_score = 0.01,
        keep_significant_only: bool = True,
        genes=None, gene_family=None,
        additional_grouping=False,
        custom_gene_family=None,
        standard_scale: bool = True,
        cluster_rows: bool = True,
        special_character_regex_pattern=None, # æŒ‡å®šéœ€è¦é¢å¤–è½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦ï¼Œä¸€èˆ¬æˆ‘ä»¬ç”¨é»˜è®¤å³å¯
        exclude_interactions=None,
        lock_celltype_direction: bool =True,
        keep_id_cp_interaction: bool =False,
        debug: bool =False
):
    '''
    ä»è¯»å–çš„cpdb_outcome_dictä¸­è¯»å‡ºç¬¦åˆæ¡ä»¶çš„ç›¸äº’ä½œç”¨è¡¨æ ¼ã€‚
    å‚è€ƒçš„æºæ–‡ä»¶æ˜¯https://github.com/zktuong/ktplotspy/blob/master/ktplotspy/plot/plot_cpdb.pyçš„plot_cpdbå‡½æ•°
    :param adata: åº”å½“æ˜¯æœ‰å®Œæ•´metadataçš„adataï¼Œä»¥ä¾¿æ¥ä¸‹æ¥ä»ä¸­æå‡ºä¿¡æ¯ã€‚
        å½“ç»™splitby_keyèµ‹å€¼æ—¶ï¼Œadata.obsåº”å…·æœ‰åˆ†ç¦»çš„"celltype_key"å’Œ"splitby_key"ä¸¤åˆ—ã€‚
    :param cell_type1/cell_type2: æœç´¢çš„ç»†èƒç±»å‹1å’Œç»†èƒç±»å‹2
    :param cpdb_outcome_dict: extract_cpdb_resultçš„è¾“å‡ºã€‚
    :param celltype_key:ç»†èƒç±»å‹åˆ—
    :param cellsign:
    :param degs_analysis:
    :param splitby_key:ç»™å‡ºadata.obsé‡Œå¯¹åº”çš„å¦ä¸€åˆ—ä½œä¸ºç»†èƒçš„åˆ†ç±»å˜é‡ï¼›
        ä¸ºäº†ä½¿å…¶æ­£å¸¸å·¥ä½œï¼Œç”¨äº CellPhoneDB çš„è¾“å…¥â€œmeta.txtâ€çš„ç¬¬äºŒåˆ—å¿…é¡»é‡‡ç”¨è¿™ç§æ ¼å¼ï¼š{splitby}_{celltype}ã€‚
    :param alpha: på€¼é˜ˆå€¼
    :param keep_significant_only:
    :param genes:
    :param gene_family:
    :param additional_grouping: è¿”å›çš„è¡¨æ ¼æ˜¯å¦éœ€è¦åé¢å¢åŠ ä¸‰åˆ—ï¼šdirectionality, classification, is_integrinï¼›è¿™ä¸€æ­¥éå¸¸è€—æ—¶
    :param custom_gene_family:
    :param standard_scale:
    :param cluster_rows:
    :param highlight_size:
    :param special_character_regex_pattern:
    :param exclude_interactions:
    :param lock_celltype_direction:é”å®šç»†èƒç±»å‹1åœ¨å·¦ä¾§ã€ç»†èƒç±»å‹2åœ¨å³ä¾§ï¼Œä¸è¿›è¡Œäº¤æ¢
    :return:
    '''
    
    # Step 1: æ•°æ®å‡†å¤‡
    means, pvals, interaction_scores, interaction_scores_mat, cellsign_mat = prepare_input(cpdb_outcome_dict, degs_analysis)
    
    col_start = (
        DEFAULT_V5_COL_START if pvals.columns[DEFAULT_CLASS_COL] == "classification" else DEFAULT_COL_START)
    
    
    # Step 2: éªŒè¯è¾“å…¥å‚æ•°
    validate_inputs(interaction_scores, cellsign, genes, gene_family)
    
    # Step 3: è·å–æŸ¥è¯¢åŸºå› æˆ–åŸºå› å®¶æ—
    gene_queries = get_gene_query(means, genes, gene_family, custom_gene_family,debug)
    
    # Step 4: å‡†å¤‡ç»†èƒç±»å‹æŸ¥è¯¢
    celltype_queries, groups = get_cell_query(metadata=metadata,means_mat=means,
                                              cell_type1=cell_type1,cell_type2=cell_type2,
                                              lock_celltype_direction=lock_celltype_direction,
                                              splitby_key=splitby_key,
                                              special_character_regex_pattern=special_character_regex_pattern,
                                              debug=debug)
    
    # Step 5: ç­›é€‰æ•°æ®
    means_matx, pvals_matx, interaction_scores_matx, cellsign_matx = filter_data(means_mat=means, pvals_mat=pvals,
                                                                                 interaction_scores=interaction_scores,interaction_scores_mat=interaction_scores_mat,cellsign=cellsign,
                                                                                 gene_query=gene_queries, cell_query=celltype_queries,
                                                                                 keep_significant_only=keep_significant_only,
                                                                                 groups=groups, # if splitby_key
                                                                                 alpha=alpha,
                                                                                 debug=debug)
    
    # Step 6: è¡Œèšç±»
    if cluster_rows:
        means_matx, pvals_matx, interaction_scores_matx, cellsign_matx = cluster_rows_by_means(means_matx, pvals_matx,
                                                                                               interaction_scores, interaction_scores_matx, cellsign, cellsign_matx)
    
    # Step 7: æ ‡å‡†åŒ–
    if standard_scale:
        means_matx = standardize_means(means_matx)
    
    # å¡«å…… NaN å€¼ä¸º 0
    means_matx.fillna(0, inplace=True)
    
    # Step 8: ç”Ÿæˆæœ€ç»ˆè¡¨æ ¼
    result = finalize_output(means_matx=means_matx, pvals_matx=pvals_matx,
                             interaction_scores=interaction_scores, interaction_scores_matx=interaction_scores_matx, cellsign=cellsign, cellsign_matx=cellsign_matx,
                             col_start=col_start,standard_scale=standard_scale,additional_grouping=additional_grouping,
                             exclude_interactions=exclude_interactions,keep_significant_only=keep_significant_only,alpha=alpha,keep_id_cp_interaction=keep_id_cp_interaction)
    result = result[result.interaction_scores >= min_interaction_score]
    return result



## ä»¥ä¸Šéƒ½æ˜¯extract_cpdb_table
# ç›®å‰çš„æå–å‡ºçš„tableè¿˜æœ‰ä¸€äº›å¯è¯»æ€§é—®é¢˜ï¼Œæˆ‘ä»¬å…ˆåœ¨ä»£ç é‡Œåšä¸€äº›è°ƒæ•´


def draw_cpdb_plot(
        dataframe,                # è¾“å…¥çš„ Pandas DataFrameï¼ŒåŒ…å«è¦ç»˜åˆ¶çš„æ•°æ®
        cmap_name: str = "viridis",  # é…è‰²æ–¹æ¡ˆåç§°
        max_size: int = 8,        # ç‚¹çš„æœ€å¤§å°ºå¯¸
        highlight_size=None,      # å¦‚æœæŒ‡å®šï¼Œåˆ™ç”¨äºé«˜äº®ç‚¹çš„å°ºå¯¸
        max_highlight_size: int = 3,  # é«˜äº®ç‚¹çš„æœ€å¤§å°ºå¯¸
        interaction_scores=None,  # å¯é€‰çš„äº¤äº’è¯„åˆ†åˆ—ï¼Œç”¨äºè°ƒæ•´é€æ˜åº¦
        default_style: bool = True,  # æ˜¯å¦åº”ç”¨é»˜è®¤æ ·å¼
        highlight_col: str = "#080000",  # é«˜äº®ç‚¹çš„é¢œè‰²
        title: str = "",          # å›¾è¡¨æ ‡é¢˜
        cellsign=None,            # å¯é€‰çš„ cellsign æ•°æ®åˆ—
        figsize=(6.4, 4.8),       # å›¾è¡¨å°ºå¯¸
        min_interaction_score: int = 0,  # æœ€å°äº¤äº’è¯„åˆ†
        scale_alpha_by_interaction_scores: bool = False,  # æ˜¯å¦æ ¹æ®äº¤äº’è¯„åˆ†è°ƒæ•´é€æ˜åº¦
        gene_family=None,         # åŸºå› å®¶æ—ä¿¡æ¯ï¼ˆç”¨äºæ ‡é¢˜ï¼‰
        alpha: float = 0.05,      # æ˜¾è‘—æ€§æ°´å¹³çš„é˜ˆå€¼
        scale_alpha_by_cellsign: bool = False,  # æ˜¯å¦æ ¹æ® cellsign è°ƒæ•´é€æ˜åº¦
        filter_by_cellsign: bool = False,  # æ˜¯å¦æ ¹æ® cellsign è¿‡æ»¤æ•°æ®
        standard_scale: bool = True  # æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–å‡å€¼åˆ—
):
    """
    ç»˜åˆ¶åŸºäºè¾“å…¥ DataFrame çš„ç»†èƒç›¸äº’ä½œç”¨å›¾è¡¨ã€‚

    Args:
        dataframe: åŒ…å«äº¤äº’æ•°æ®çš„ Pandas DataFrameï¼Œç›´æ¥ä½¿ç”¨extract_cpdb_tableçš„çš„è¾“å‡ºç»“æœ
        cmap_name: æŒ‡å®šé¢œè‰²æ˜ å°„åç§°ã€‚
        max_size: è®¾ç½®ç‚¹çš„æœ€å¤§å°ºå¯¸ã€‚
        highlight_size: æŒ‡å®šç”¨äºé«˜äº®ç‚¹çš„å°ºå¯¸ã€‚
        max_highlight_size: é«˜äº®ç‚¹çš„æœ€å¤§å°ºå¯¸ï¼ˆé»˜è®¤ 3ï¼‰ã€‚
        interaction_scores: ç”¨äºæ§åˆ¶ç‚¹é€æ˜åº¦çš„äº¤äº’è¯„åˆ†åˆ—ã€‚
        default_style: æ˜¯å¦å¯ç”¨é»˜è®¤æ ·å¼ï¼ˆå½±å“é¢œè‰²æ˜ å°„å’Œå¡«å……ï¼‰ã€‚
        highlight_col: é«˜äº®ç‚¹çš„é¢œè‰²ã€‚
        title: å›¾è¡¨çš„æ ‡é¢˜ã€‚
        cellsign: cellsign æ•°æ®åˆ—ï¼Œç”¨äºè¿‡æ»¤æˆ–è°ƒæ•´é€æ˜åº¦ã€‚
        figsize: å›¾è¡¨çš„å®½åº¦å’Œé«˜åº¦ã€‚
        min_interaction_score: ç­›é€‰çš„æœ€å°äº¤äº’è¯„åˆ†ã€‚
        scale_alpha_by_interaction_scores: æ˜¯å¦åŸºäºäº¤äº’è¯„åˆ†è°ƒæ•´é€æ˜åº¦ã€‚
        gene_family: åŸºå› å®¶æ—åç§°ï¼Œç”¨äºå›¾è¡¨æ ‡é¢˜ã€‚
        alpha: æ˜¾è‘—æ€§æ°´å¹³çš„é˜ˆå€¼ã€‚
        scale_alpha_by_cellsign: æ˜¯å¦åŸºäº cellsign è°ƒæ•´é€æ˜åº¦ã€‚
        filter_by_cellsign: æ˜¯å¦æ ¹æ® cellsign çš„é˜ˆå€¼è¿‡æ»¤æ•°æ®ã€‚
        standard_scale: æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–çš„å‡å€¼åˆ—ï¼ˆ"scaled_means"ï¼‰ã€‚
        keep_id_cp_interaction: æ˜¯å¦ä¿ç•™å®Œæ•´çš„äº¤äº’ç»„æ ‡è¯†ç¬¦ã€‚

    Returns:
        ä¸€ä¸ª ggplot å›¾å¯¹è±¡ï¼Œç”¨äºå¯è§†åŒ–ç»†èƒç›¸äº’ä½œç”¨ã€‚
    """
    
    def configure_ggplot(df, colm, stroke, default_style, alpha_by_interaction = False, alpha_by_cellsign = False):
        aes_params = {
            "x": "celltype_group",
            "y": "interaction_group",
            "size": colm,
            "stroke": stroke
        }
        if alpha_by_interaction:
            aes_params["alpha"] = "interaction_scores"
        elif alpha_by_cellsign:
            aes_params["alpha"] = "cellsign"
        else:
            return None
        
        if default_style:
            aes_params.update({"colour": "significant", "fill": colm})
        else:
            aes_params.update({"colour": colm, "fill": "significant"})
        return ggplot(df, aes(**aes_params))
    
    
    df = dataframe.copy()
    colm = "scaled_means" if standard_scale else "means"

    # set global figure size
    options.figure_size = figsize
    if highlight_size is not None:
        max_highlight_size = highlight_size
        stroke = "x_stroke"
    else:
        stroke = "neglog10p"
    
    # plotting
    print(highlight_size);
    print(stroke)
    if interaction_scores is not None:
        df = df[df.interaction_scores >= min_interaction_score]
    elif cellsign is not None and filter_by_cellsign:
        df = df[df.cellsign >= DEFAULT_CELLSIGN_ALPHA]
    else:
        print("Skip filtering by interaction score or cellsign.")
    
    if interaction_scores and scale_alpha_by_interaction_scores:
        print("Set alpha by interaction_scores.")
        if default_style or all(df["significant"] == "no"):
            default_style = True
            g = configure_ggplot(df, colm, stroke, default_style, alpha_by_interaction=True)
        else:
            highlight_col = "#FFFFFF"  # enforce this
            g = configure_ggplot(df, colm, stroke, default_style, alpha_by_interaction=True)
    elif interaction_scores and not scale_alpha_by_interaction_scores: # å†²çªæƒ…å†µ
        print("Skip transparency setting: interaction_scores setted but not scale_alpha_by_interaction_scores.")
        g = None
    elif cellsign and scale_alpha_by_cellsign:
        print("Set alpha by cellsign.")
        if default_style or all(df["significant"] == "no"):
            default_style = True
            g = configure_ggplot(df, colm, stroke, default_style, alpha_by_cellsign=True)
        else:
            highlight_col = "#FFFFFF"  # enforce this
            g = configure_ggplot(df, colm, stroke, default_style, alpha_by_cellsign=True)
    elif cellsign and not scale_alpha_by_cellsign:
        print("Skip transparency setting: cellsign setted but not scale_alpha_by_cellsign.")
        g = None
    elif interaction_scores is None and cellsign is None:
        print("Skip transparency setting: both interaction score and cellsign is none.")
        g = None
    
    if g is None:
        if default_style or all(df["significant"] == "no"):
            g = configure_ggplot(df, colm, stroke, default_style) # ä¸è®¾ç½®alpha
        else:
            highlight_col = "#FFFFFF"  # enforce this
            g = configure_ggplot(df, colm, stroke, default_style) # ä¸è®¾ç½®alphaï¼ŒåŒæ—¶ä¹Ÿä¸æ˜¯defualt style
    
    g = (
            g
            + geom_point(
        na_rm=True,
    )
            + theme_bw()
            + theme(
        axis_text_x=element_text(angle=90, hjust=0, colour="#000000"),
        axis_text_y=element_text(colour="#000000"),
        axis_ticks=element_blank(),
        axis_title_x=element_blank(),
        axis_title_y=element_blank(),
        legend_key=element_rect(alpha=0, width=0, height=0),
        legend_direction="vertical",
        legend_box="horizontal",
    )
            + scale_size_continuous(range=(0, max_size), aesthetics=["size"])
            + scale_size_continuous(range=(0, max_highlight_size), aesthetics=["stroke"])
    )
    if default_style:
        g = (
                g
                + scale_colour_manual(values=highlight_col, na_translate=False)
                + guides(
            fill=guide_colourbar(barwidth=4, label=True, ticks=True, draw_ulim=True, draw_llim=True, order=1),
            size=guide_legend(
                reverse=True,
                order=2,
            ),
            stroke=guide_legend(
                reverse=True,
                order=3,
            ),
        )
                + scale_fill_continuous(cmap_name=cmap_name)
        )
    else:
        g = (
                g
                + scale_fill_manual(values=highlight_col, na_translate=False)
                + guides(
            colour=guide_colourbar(barwidth=4, label=True, ticks=True, draw_ulim=True, draw_llim=True, order=1),
            size=guide_legend(
                reverse=True,
                order=2,
            ),
            stroke=guide_legend(
                reverse=True,
                order=3,
            ),
        )
        )
        df2 = df.copy()
        for i in df2.index:
            if df2.at[i, "pvals"] < alpha:
                df2.at[i, colm] = np.nan
        g = (
                g
                + geom_point(aes(x="celltype_group", y="interaction_group", colour=colm, size=colm), df2,
                             inherit_aes=False, na_rm=True)
                + scale_colour_continuous(cmap_name=cmap_name)
        )
    
    if highlight_size is not None:
        g = g + guides(stroke=None)
    if (interaction_scores is not None) and scale_alpha_by_interaction_scores:
        g = g + scale_alpha_continuous(breaks=(0, 25, 50, 75, 100))
    if (cellsign is not None) and scale_alpha_by_cellsign:
        g = g + scale_alpha_continuous(breaks=(0, 1))
    if title != "":
        g = g + ggtitle(title)
    elif gene_family is not None:
        if isinstance(gene_family, list):
            gene_family = ", ".join(gene_family)
        g = g + ggtitle(gene_family)
    return g



    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    







     

  

     

   

      

   

  

   

   

   

   

   

   

   

   

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   