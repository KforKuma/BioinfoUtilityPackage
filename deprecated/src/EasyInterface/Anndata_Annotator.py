import pandas as pd
import anndata
import os,gc
# è¿ç§»å®Œæˆï¼Œæ‰“åŒ…æˆæ–°çš„ class ObsEditor


def make_new_ident(anno_list, anno_obs_key, adata_obs_key_list, adata):
    """
    å°†åˆ—è¡¨å½¢å¼çš„èšç±»ç»“æžœçš„èº«ä»½åˆ¤å®šï¼Œä¿®è®¢ï¼ˆæ”¾å…¥ï¼‰anndataæ–‡ä»¶ä¸­
    :param anno_list: æŒ‰ç…§[identity_for_cluster1, identity_for_cluster2, ...,]æ ¼å¼å†™å¥½çš„ç»†èƒžäºšç¾¤èº«ä»½å®šä¹‰
    :param anno_obs_key: ä¸Šè¿°åˆ—è¡¨æ‰€å‚ç…§çš„obs_keyï¼Œä¸€èˆ¬ä¸ºè¯¸å¦‚â€˜leiden0_5â€™å½¢å¼çš„æ•°å­—èšç±»ä¿¡æ¯åˆ—
    :param adata_obs_key_list: åˆ—è¡¨ï¼ŒåŒ…å«æ‰€éœ€è¦æ›´æ”¹çš„.obsé¡¹ç›®
    :param adata: éœ€è¦ä¿®è®¢çš„anndataæ–‡ä»¶
    :return: è¿”å›žä¿®è®¢åŽçš„anndataæ–‡ä»¶
    """
    cl_annotation = dict()
    for i in range(0, len(anno_list)):
        cl_annotation[str(i)] = anno_list[i]
    print(cl_annotation)
    for i in adata_obs_key_list:
        del adata.obs[i]
        adata.obs[i] = adata.obs[anno_obs_key].map(cl_annotation)
    return adata


def copy_all_ident(adata_children_obs_key, adata_parent_obs_key, adata_children, adata_parent):
    """
    æŒ‰ç…§adata_childrençš„æŸä¸€obs_keyå®šä¹‰å¥½çš„ç»†èƒžä¿¡æ¯ï¼Œä¿®æ­£adata_parentçš„ç»†èƒžä¿¡æ¯
    :param adata_children_obs_key: æ‰€ä¾æ®çš„adata_childrençš„obs_key
    :param adata_parent_obs_key: adata_parentéœ€è¦ä¿®è®¢çš„obs_key
    :param adata_children: ä¸€èˆ¬ä¸ºæŸä¸€ç»†åˆ†äºšç¾¤
    :param adata_parent: ä¸€èˆ¬ä¸ºæŸä¸€å¤§ç±»ç¾¤ï¼Œæˆ–åŽŸå§‹anndataæ–‡ä»¶
    :return: æ— ï¼Œä½†æ‰“å°ä¿®è®¢æ‰€æ¶‰åŠçš„ç»†èƒžèº«ä»½åŠå…¶åœ¨å¤§ç¾¤ä¸­çš„æ•°é‡
    """
    adata_parent.obs[adata_parent_obs_key] = adata_parent.obs[adata_parent_obs_key].tolist()
    # adata_parent.obs[adata_parent_obs_key] = pd.Series(adata_parent.obs[adata_parent_obs_key].tolist(), ) # deprecated
    for i in adata_children.obs[adata_children_obs_key].unique().tolist():
        print(i)
        index = adata_parent.obs_names[(adata_children.obs[adata_parent_obs_key] == i)]
        adata_parent.obs.loc[index, adata_parent_obs_key] = i
        print(len(adata_parent[adata_parent.obs[adata_parent_obs_key] == i]))


def change_one_ident_fast(adata, key, old, new):
    """
    æ›´å¿«é€Ÿåœ°æ›¿æ¢åˆ†ç±»åˆ—ä¸­çš„å€¼ï¼Œä»…å½“å¿…è¦æ—¶æ·»åŠ ç±»åˆ«ï¼Œä¸”ä¸æ‰§è¡Œæ…¢çš„removeæ“ä½œ
    """
    if pd.api.types.is_categorical_dtype(adata.obs[key]):
        if new not in adata.obs[key].cat.categories:
            adata.obs[key] = adata.obs[key].cat.add_categories([new])
        # å¸ƒå°”ç´¢å¼•ä¸€æ¬¡å®Œæˆ
        mask = adata.obs[key] == old
        adata.obs.loc[mask, key] = new
        print(f"Replaced {mask.sum()} cells from '{old}' to '{new}'.")
        # å–æ¶ˆ remove_categories â€”â€” æ…¢ä¸”é€šå¸¸æ²¡å¿…è¦
    else:
        mask = adata.obs[key] == old
        adata.obs.loc[mask, key] = new
        print(f"Replaced {mask.sum()} cells from '{old}' to '{new}'.")


def generate_subclusters_by_identity(
        adata: anndata.AnnData,
        identity_key: str = "Subset_Identity",
        cell_idents_list: list = None,
        resolutions: list = [0.5, 1.0],
        output_dir: str = ".",
        use_rep: str = "X_scVI",
        subcluster_func=None,
        n_neighbors: int = 20,
        filename_prefix: str = "Step06_Subset"
):
    """
    å¯¹æŒ‡å®šçš„ç»†èƒžç¾¤ä½“è¿›è¡Œå­èšç±»åˆ†æžå¹¶ä¿å­˜ä¸ºç‹¬ç«‹æ–‡ä»¶ã€‚

    Parameters:
        adata: AnnData
            åŽŸå§‹ AnnData æ•°æ®å¯¹è±¡ã€‚
        identity_key: str
            ç”¨äºŽé€‰æ‹©å­é›†çš„ obs åˆ—åï¼Œé»˜è®¤ "Subset_Identity"ã€‚
        identities: list
            éœ€è¦å¤„ç†çš„ç»†èƒžèº«ä»½åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨è¯¥åˆ—ä¸­çš„æ‰€æœ‰å”¯ä¸€å€¼ã€‚
        resolutions: list
            èšç±»åˆ†è¾¨çŽ‡åˆ—è¡¨ï¼Œä¾‹å¦‚ [0.5, 1.0]ã€‚
        output_dir: str
            å­é›† h5ad æ–‡ä»¶çš„ä¿å­˜ç›®å½•ã€‚
        use_rep: str
            ç”¨äºŽèšç±»çš„è¡¨ç¤ºç©ºé—´ï¼ˆä¾‹å¦‚ "X_scVI"ï¼‰ã€‚
        subcluster_func: callable
            èšç±»å‡½æ•°ï¼Œä¾‹å¦‚ subcluster(adata_subset, ...)ï¼Œå¿…é¡»ä¼ å…¥ã€‚
        n_neighbors: int
            èšç±»æ—¶ä½¿ç”¨çš„é‚»å±…æ•°ã€‚
        filename_prefix: str
            è¾“å‡ºæ–‡ä»¶åå‰ç¼€ã€‚
    """
    assert subcluster_func is not None, "è¯·ä¼ å…¥ subcluster å‡½æ•°ä½œä¸ºå‚æ•° subcluster_func"
    os.makedirs(output_dir, exist_ok=True)
    if cell_idents_list is None:
        cell_idents_list = adata.obs[identity_key].unique()
    
    for ident in cell_idents_list:
        print(f"\nðŸ” Now processing subset: {ident}")
        adata_subset = adata[adata.obs[identity_key] == ident].copy()
        
        # åˆ é™¤ leiden_res ç›¸å…³åˆ—ï¼ˆobsï¼‰
        leiden_cols = [col for col in adata_subset.obs.columns if 'leiden_res' in col]
        if leiden_cols:
            adata_subset.obs.drop(columns=leiden_cols, inplace=True)
        
        # åˆ é™¤ leiden_res ç›¸å…³é¡¹ï¼ˆunsï¼‰
        leiden_keys = [key for key in adata_subset.uns.keys() if 'leiden_res' in key]
        for key in leiden_keys:
            del adata_subset.uns[key]
        
        # å­èšç±»
        adata_subset = subcluster_func(
            adata_subset,
            n_neighbors=n_neighbors,
            n_pcs=min(adata.obsm[use_rep].shape[1], 50),
            resolutions=resolutions,
            use_rep=use_rep
        )
        
        # ä¿å­˜
        filename = os.path.join(output_dir, f"{filename_prefix}_{ident}.h5ad")
        adata_subset.write(filename)
        print(f"ðŸ’¾ Saved to {filename}")
        
        # æ¸…ç†å†…å­˜
        del adata_subset
        gc.collect()


def run_deg_on_subsets(
        cell_idents_list: list = None,
        resolutions: list = [0.5, 1.0],
        base_input_path: str = ".",
        base_output_path: str = ".",
        deg_method: str = "wilcoxon",
        save_plot: bool = True,
        plot_gene_num: int = 5,
        use_raw: bool = True,
        obs_subset: bool = False,
        save_prefix: str = "Step06_Subset",
        output_suffix: str = "_DEG.h5ad",
        easy_deg_func=None,
):
    """
    å¯¹ AnnData ä¸­ä¸åŒå­é›†æ‰§è¡Œ DEG åˆ†æžï¼ˆåŸºäºŽ leiden èšç±»ï¼‰ã€‚

    Parameters:
        resolutions: list
            éœ€è¦è¿è¡Œ DEG çš„ leiden åˆ†è¾¨çŽ‡åˆ—è¡¨ã€‚
        base_input_path: str
            å­é›† h5ad æ–‡ä»¶çš„åŸºç¡€ç›®å½•ã€‚
        base_output_path: str
            è¾“å‡º DEG æ–‡ä»¶çš„åŸºç¡€ç›®å½•ã€‚
        deg_method: str
            ä½¿ç”¨çš„ DEG æ–¹æ³•ï¼Œä¾‹å¦‚ "wilcoxon"ã€‚
        save_plot: bool
            æ˜¯å¦ä¿å­˜ DEG çš„ marker gene å›¾ã€‚
        plot_gene_num: int
            æ¯ä¸ª cluster æ˜¾ç¤ºçš„ top marker gene æ•°é‡ã€‚
        use_raw: bool
            æ˜¯å¦ä½¿ç”¨åŽŸå§‹è¡¨è¾¾å€¼è¿›è¡Œ DEGã€‚
        save_prefix: str
            è¾“å…¥è¾“å‡ºæ–‡ä»¶åçš„å‰ç¼€éƒ¨åˆ†ã€‚
        output_suffix: str
            è¾“å‡º DEG åŽç¼€ï¼Œä¾‹å¦‚ "_DEG.h5ad"ã€‚
        easy_deg_func: callable
            ä½ è‡ªå·±çš„ easy_DEG å‡½æ•°ï¼Œå¿…é¡»ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚
    """
    
    assert easy_deg_func is not None, "è¯·ä¼ å…¥ easy_DEG å‡½æ•°ä½œä¸ºå‚æ•° easy_deg_func"
    
    for cell_ident in cell_idents_list:
        print(f"\n=== Now processing subset: {cell_ident} ===")
        
        input_file = os.path.join(base_input_path, f"{save_prefix}_{cell_ident}.h5ad")
        print(f"Loading file: {input_file}")
        adata_subset = anndata.read_h5ad(input_file)
        
        for res in resolutions:
            group_key = f"leiden_res{res}"
            print(f"Running easy_DEG for resolution {res} with group key '{group_key}'...")
            os.makedirs(base_output_path,exist_ok=True)
            adata_subset = easy_deg_func(
                adata_subset,
                save_addr=base_output_path,
                filename=f"Secondary_Cluster_{cell_ident}(For clean up)",
                obs_key=group_key,
                save_plot=save_plot,
                plot_gene_num=plot_gene_num,
                downsample=obs_subset,
                method=deg_method,
                use_raw=use_raw
            )
            print(f"Finished DEG at resolution {res}.")
        
        output_file = os.path.join(base_output_path, f"{save_prefix}_{cell_ident}{output_suffix}")
        adata_subset.write_h5ad(output_file)
        print(f"Saved DEG results to: {output_file}")


def apply_assignment_annotations(
        assignment_file: str,
        adata_main: anndata.AnnData,
        h5ad_dir: str,
        obs_key_col: str = "Obs_key_select",
        subset_file_col: str = "Subset_File",
        subset_no_col: str = "Subset_No",
        identity_col: str = "Identity",
        output_key: str = "Subset_Identity",
        fillna_from_col: str = None
):
    """
    æ ¹æ® assignment è¡¨æ ¼æ›´æ–°ä¸» AnnData å¯¹è±¡ä¸­çš„ç»†èƒžäºšç¾¤æ³¨é‡Šã€‚

    å‚æ•°:
    - assignment_file: assignment Excel æ–‡ä»¶è·¯å¾„
    - adata_main: ä¸» AnnData å¯¹è±¡ï¼ˆå°†è¢«æ›´æ–°ï¼‰
    - h5ad_dir: å­é›† h5ad æ–‡ä»¶æ‰€åœ¨ç›®å½•
    - obs_key_col, subset_file_col, subset_no_col, identity_col: assignment è¡¨æ ¼ä¸­å¯¹åº”çš„åˆ—å
    - output_key: ä¸» AnnData ä¸­éœ€è¦å†™å…¥çš„åˆ—å
    - fillna_from_col: ç”¨äºŽå¡«å…… output_key ä¸­ç©ºå€¼çš„å¤‡ç”¨åˆ—
    """
    
    excel_data = pd.ExcelFile(assignment_file)
    assignment_sheet = excel_data.parse(excel_data.sheet_names[0])
    
    for subset_filename in set(assignment_sheet[subset_file_col]):
        print(f"\nNow reading {subset_filename} subset.")
        input_path = f"{h5ad_dir}/{subset_filename}"
        adata_subset = anndata.read(input_path)
        
        # æå– obs_key
        obs_key_series = assignment_sheet.loc[
            assignment_sheet[subset_file_col] == subset_filename, obs_key_col
        ].dropna().drop_duplicates()
        obs_key = obs_key_series.iat[0] if not obs_key_series.empty else None
        print(f"Obs key for {subset_filename}: {obs_key}")
        
        # identity æ˜ å°„å­—å…¸
        subset_data = assignment_sheet[assignment_sheet[subset_file_col] == subset_filename]
        result_dict = subset_data.set_index(subset_no_col)[identity_col].to_dict()
        updated_dict = {str(k): v for k, v in result_dict.items()}
        print(f"Created identity dictionary for {subset_filename} with {len(updated_dict)} entries")
        
        adata_subset.obs["tmp"] = adata_subset.obs[obs_key].map(updated_dict)
        unique_identities = adata_subset.obs["tmp"].dropna().unique()
        
        # å¦‚æžœ output_key ä¸å­˜åœ¨ï¼Œåˆ™åˆå§‹åŒ–ä¸ºç©ºåˆ—
        if output_key not in adata_main.obs.columns:
            adata_main.obs[output_key] = pd.Series(index=adata_main.obs_names, dtype="str")
        
        # å¤„ç† Categorical ç±»åž‹çš„åˆ—ï¼Œæ‰©å±•ç±»åˆ«
        if pd.api.types.is_categorical_dtype(adata_main.obs[output_key]):
            existing_categories = set(adata_main.obs[output_key].cat.categories)
            new_categories = set(unique_identities) - existing_categories
            if new_categories:
                adata_main.obs[output_key] = adata_main.obs[output_key].cat.add_categories(list(new_categories))
        
        for cell_identity in unique_identities:
            print(f"  Processing identity: {cell_identity}")
            index = adata_subset.obs_names[adata_subset.obs["tmp"] == cell_identity]
            adata_main.obs.loc[index, output_key] = cell_identity
            updated_cells = (adata_main.obs[output_key] == cell_identity).sum()
            print(f"  -> Updated {updated_cells} cells with identity '{cell_identity}'")
    
    # ç”¨å…¶ä»–åˆ—è¡¥å…¨ç¼ºå¤±å€¼
    if fillna_from_col and fillna_from_col in adata_main.obs.columns:
        n_missing = adata_main.obs[output_key].isna().sum()
        adata_main.obs[output_key] = adata_main.obs[output_key].fillna(adata_main.obs[fillna_from_col])
        print(f"Filled {n_missing} missing '{output_key}' values using '{fillna_from_col}'")
    
    print("\nAll assignments applied.")
